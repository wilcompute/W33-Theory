from collections import defaultdict, Counter
from pathlib import Path
from typing import Iterable, Set, Tuple, Dict, FrozenSet


def load_triangles(path: Path) -> Iterable[Tuple[int, int, int]]:
    """Load triangle triples (u,v,w) from CSV. Try pandas first, otherwise fall back to lightweight parsing."""
    try:
        import pandas as pd

        df = pd.read_csv(path)
        for r in df.itertuples(index=False):
            yield int(r.u), int(r.v), int(r.w)
    except Exception:
        # Lightweight fallback parser (no pandas required)
        with path.open("r", encoding="utf-8") as f:
            header = next(f)
            for line in f:
                line = line.strip()
                if not line:
                    continue
                parts = line.split(",")
                try:
                    u = int(parts[0])
                    v = int(parts[1])
                    w = int(parts[2])
                except Exception:
                    # skip malformed line
                    continue
                yield u, v, w


def points_set(triangles: Iterable[Tuple[int, int, int]]) -> Set[int]:
    pts = set()
    for u, v, w in triangles:
        pts.update((u, v, w))
    return pts


def neighborhoods_from_triangles(triangles: Iterable[Tuple[int, int, int]]) -> Dict[int, Set[int]]:
    nbr = defaultdict(set)
    for u, v, w in triangles:
        # each vertex is connected to the other two in the triangle
        nbr[u].update((v, w))
        nbr[v].update((u, w))
        nbr[w].update((u, v))
    return {p: set(ns) for p, ns in nbr.items()}


def point_hyperplanes(neighborhoods: Dict[int, Set[int]]) -> Dict[int, FrozenSet[int]]:
    # Define hyperplane associated to point p as the neighborhood of p plus p itself
    return {p: frozenset(ns | {p}) for p, ns in neighborhoods.items()}


def veldkamp_space_from_generators(gens: Iterable[FrozenSet[int]]) -> Set[FrozenSet[int]]:
    # Veldkamp-like space generated by symmetric differences over GF(2)
    gens = list(gens)
    space = set()
    n = len(gens)
    # Generate all linear combinations (2^n) is expensive if n large; instead use iterative closure
    space = set(gens)
    changed = True
    while changed:
        changed = False
        new_sets = set()
        for a in space:
            for b in space:
                sd = frozenset(a.symmetric_difference(b))
                if sd not in space:
                    new_sets.add(sd)
        if new_sets:
            space |= new_sets
            changed = True
    # include empty set and universal set as conventional
    space.add(frozenset())
    universal = frozenset().union(*gens) if gens else frozenset()
    space.add(universal)
    return space


def gf2_rank_from_generators(gens: Iterable[FrozenSet[int]]) -> int:
    """Compute GF(2) rank of the vector space spanned by the generators (as indicator vectors).

    gens: iterable of sets of point labels (ints). The function builds integer bitmasks and performs
    Gaussian elimination over GF(2) to compute rank.
    """
    gens = list(gens)
    if not gens:
        return 0
    pts = sorted(set().union(*gens))
    idx = {p: i for i, p in enumerate(pts)}
    rows = []
    for g in gens:
        mask = 0
        for p in g:
            mask |= 1 << idx[p]
        if mask:
            rows.append(mask)
    # Gaussian elimination over GF(2)
    rank = 0
    i = 0
    while rows:
        # pick pivot with highest bit
        pivot = max(rows)
        rows.remove(pivot)
        rank += 1
        # eliminate pivot bit from others
        bit = pivot & -pivot
        rows = [r ^ pivot if (r & pivot) else r for r in rows]
        # remove zeros
        rows = [r for r in rows if r]
    return rank


def expected_veldkamp_count_from_rank(rank: int) -> int:
    return 1 << rank


def summarize_veldkamp(triangle_csv: Path) -> Dict:
    triangles = list(load_triangles(triangle_csv))
    pts = points_set(triangles)
    neighborhoods = neighborhoods_from_triangles(triangles)
    hyperplanes = point_hyperplanes(neighborhoods)
    gens = list(hyperplanes.values())

    # GF(2) linear algebra invariants
    gf2_rank = gf2_rank_from_generators(gens)
    expected_n_veldkamp = expected_veldkamp_count_from_rank(gf2_rank)

    # enumerate the Veldkamp space only when the rank is small enough
    ENUMERATE_RANK_LIMIT = 20
    veld = None
    veldkamp_size_hist = {}
    n_veldkamp = expected_n_veldkamp
    veldkamp_enumerated = False
    if gf2_rank <= ENUMERATE_RANK_LIMIT:
        veld = veldkamp_space_from_generators(gens)
        n_veldkamp = len(veld)
        veldkamp_size_hist = dict(Counter(len(s) for s in veld))
        veldkamp_enumerated = True

    gen_size_hist = Counter(len(g) for g in gens)
    deg_hist = Counter(len(neighborhoods.get(p, [])) for p in pts)

    return {
        "n_points": len(pts),
        "n_triangles": len(triangles),
        "n_generators": len(gens),
        "generator_size_hist": dict(gen_size_hist),
        "gf2_rank": gf2_rank,
        "expected_n_veldkamp": expected_n_veldkamp,
        "n_veldkamp": n_veldkamp,
        "veldkamp_enumerated": veldkamp_enumerated,
        "veldkamp_size_hist": veldkamp_size_hist,
        "degree_hist": dict(deg_hist),
    }


if __name__ == "__main__":
    import argparse
    import json

    p = argparse.ArgumentParser()
    p.add_argument("csv")
    p.add_argument("--out", default="veld_summary.json")
    args = p.parse_args()

    summary = summarize_veldkamp(Path(args.csv))
    with open(args.out, "w", encoding="utf-8") as f:
        json.dump(summary, f, indent=2, default=str)
    print("Wrote", args.out)
