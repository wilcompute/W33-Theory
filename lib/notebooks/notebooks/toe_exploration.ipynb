{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef1c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concluding notes\n",
    "\n",
    "print(\"Notebook complete. Figures saved under data/_docs/figures/. See the digest for commentary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10723e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance profiling & micro-optimizations\n",
    "\n",
    "import timeit\n",
    "import cProfile\n",
    "\n",
    "# Simple micro-benchmark example\n",
    "data = list(range(10_0000))\n",
    "\n",
    "def sum_loop(d):\n",
    "    s = 0\n",
    "    for x in d:\n",
    "        s += x\n",
    "    return s\n",
    "\n",
    "print(\"timeit loop:\", timeit.timeit(lambda: sum_loop(data), number=10))\n",
    "print(\"timeit built-in sum:\", timeit.timeit(lambda: sum(data), number=10))\n",
    "\n",
    "# cProfile on a small function\n",
    "cProfile.run('sum_loop(data)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9931f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit tests with pytest (example functions + tests)\n",
    "\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "# A trivial test; in real use you'd put these in tests/ and run `pytest`\n",
    "\n",
    "def test_add():\n",
    "    assert add(1, 2) == 3\n",
    "\n",
    "print('Run `pytest -q` in the repo root to execute tests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd164aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load repo digest and create targeted figures\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "key_lines = Path('data') / '_docs' / 'toe_key_lines.csv'\n",
    "if not key_lines.exists():\n",
    "    print('Warning: toe_key_lines.csv not found in data/_docs; run scripts/generate_toe_key_lines.py first')\n",
    "else:\n",
    "    df = pd.read_csv(key_lines, encoding='utf-8-sig')\n",
    "    print('Loaded', len(df), 'rows from', key_lines)\n",
    "\n",
    "    # Boxplot: mean_abs_delta by unique_k_mod6\n",
    "    if 'mean_abs_delta' in df.columns and 'unique_k_mod6' in df.columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.boxplot(x='unique_k_mod6', y='mean_abs_delta', data=df)\n",
    "        plt.title('mean_abs_delta by unique_k_mod6')\n",
    "        out = Path('data') / '_docs' / 'figures' / 'mean_abs_delta_by_kmod6.png'\n",
    "        plt.savefig(out, bbox_inches='tight')\n",
    "        print('Saved', out)\n",
    "\n",
    "    # Scatter: native_mean_abs_delta vs prior_score\n",
    "    if 'native_mean_abs_delta' in df.columns and 'prior_score' in df.columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        s = df.get('node_commutator_score', None)\n",
    "        sizes = (s.fillna(s.mean())*200).clip(20,300) if s is not None else 40\n",
    "        sns.scatterplot(x='native_mean_abs_delta', y='prior_score', hue=df.get('in_top_native', False), size=sizes, data=df)\n",
    "        plt.title('prior_score vs native_mean_abs_delta')\n",
    "        out = Path('data') / '_docs' / 'figures' / 'prior_vs_native_scatter.png'\n",
    "        plt.savefig(out, bbox_inches='tight')\n",
    "        print('Saved', out)\n",
    "\n",
    "    # Histogram: k12_entropy\n",
    "    if 'k12_entropy' in df.columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        sns.histplot(df['k12_entropy'].dropna(), bins=30, kde=True)\n",
    "        plt.title('k12_entropy distribution')\n",
    "        out = Path('data') / '_docs' / 'figures' / 'k12_entropy_hist.png'\n",
    "        plt.savefig(out, bbox_inches='tight')\n",
    "        print('Saved', out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cefcc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving & loading artifacts (joblib + CSV/Parquet)\n",
    "from joblib import dump, load\n",
    "from pathlib import Path\n",
    "\n",
    "artifacts = Path('data') / '_workbench' / '00_meta' / 'artifacts'\n",
    "artifacts.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "obj = {'a': 1, 'b': 2}\n",
    "dump(obj, artifacts / 'example_joblib_v1.joblib')\n",
    "print('Saved joblib:', artifacts / 'example_joblib_v1.joblib')\n",
    "\n",
    "# Save a tiny DataFrame\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'x':[1,2,3],'y':[4,5,6]})\n",
    "df.to_csv(artifacts / 'example_df.csv', index=False)\n",
    "print('Saved CSV:', artifacts / 'example_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505d15c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation & metrics (ROC, confusion matrix)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# quick example from synthetic classification earlier (will be available in the notebook)\n",
    "try:\n",
    "    y_true\n",
    "    y_pred\n",
    "    y_score\n",
    "except NameError:\n",
    "    # fallback small sample\n",
    "    y_true = [0,1,0,1,1,0]\n",
    "    y_pred = [0,1,0,1,0,0]\n",
    "    y_score = [0.1, 0.9, 0.2, 0.8, 0.4, 0.3]\n",
    "\n",
    "print('Accuracy', accuracy_score(y_true, y_pred))\n",
    "print('Classification report:\\n', classification_report(y_true, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.title('Confusion matrix')\n",
    "plt.xlabel('Pred')\n",
    "plt.ylabel('True')\n",
    "plt.savefig('data/_docs/figures/example_confusion_matrix.png', bbox_inches='tight')\n",
    "print('Saved confusion matrix example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6949305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple ML model: pipeline + cross-validation\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X, y = make_classification(n_samples=500, n_features=10, n_informative=4, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=200))])\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Train accuracy', pipe.score(X_train, y_train))\n",
    "print('Test accuracy', pipe.score(X_test, y_test))\n",
    "print('CV mean accuracy', cross_val_score(pipe, X, y, cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8ad0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data visualization examples (distributions, scatter, saving figures)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Small example dataset\n",
    "rng = np.random.default_rng(0)\n",
    "df = pd.DataFrame({'a': rng.normal(size=200), 'b': rng.normal(loc=2.0, scale=1.5, size=200)})\n",
    "\n",
    "plt.figure()\n",
    "sns.histplot(df['a'], kde=True)\n",
    "plt.title('Distribution of a')\n",
    "plt.savefig('data/_docs/figures/dist_a.png', bbox_inches='tight')\n",
    "print('Saved dist_a.png')\n",
    "\n",
    "plt.figure()\n",
    "sns.scatterplot(x='a', y='b', data=df)\n",
    "plt.title('Scatter a vs b')\n",
    "plt.savefig('data/_docs/figures/scatter_a_b.png', bbox_inches='tight')\n",
    "print('Saved scatter_a_b.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c9c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas DataFrame manipulation examples\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "arr = np.arange(12).reshape(4,3)\n",
    "df = pd.DataFrame(arr, columns=['x','y','z'])\n",
    "df['sum'] = df.sum(axis=1)\n",
    "print(df.head())\n",
    "print('Groupby sum by z%2 ->')\n",
    "print(df.groupby(df['z']%2)['sum'].sum())\n",
    "\n",
    "# Handle missing values\n",
    "df2 = df.copy()\n",
    "df2.loc[1,'x'] = None\n",
    "print('Fillna ->')\n",
    "print(df2.fillna(df2.mean()))\n",
    "\n",
    "# Export\n",
    "df.to_csv('data/_workbench/00_meta/example_df_out.csv', index=False)\n",
    "print('Exported example_df_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed33f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy array operations\n",
    "import numpy as np\n",
    "arr = np.arange(12).reshape(3,4)\n",
    "print('Array:\\n', arr)\n",
    "print('Sum axis 0:', arr.sum(axis=0))\n",
    "print('Mean:', arr.mean())\n",
    "print('Broadcast add:', arr + 1)\n",
    "assert arr.shape == (3,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e65a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic data generation (classification + regression)\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xc, yc = make_classification(n_samples=300, n_features=8, n_informative=3, random_state=1)\n",
    "Xr, yr = make_regression(n_samples=300, n_features=6, noise=0.1, random_state=2)\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(Xc, yc, test_size=0.25, random_state=42)\n",
    "print('Classification shapes', Xc_train.shape, Xc_test.shape)\n",
    "print('Regression shapes', Xr.shape, yr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14f62c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup & imports\n",
    "# If a required package is missing, you can uncomment and run the pip install lines below.\n",
    "# !pip install pandas matplotlib seaborn scikit-learn joblib pytest\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Profiling & testing\n",
    "import timeit\n",
    "import cProfile\n",
    "\n",
    "# Ensure figures directory exists\n",
    "fig_dir = Path('data') / '_docs' / 'figures'\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Imports OK. Figures will be written to', fig_dir)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
